---
title: "hw2"
author: "Zitao Zhang"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(janitor)
library(readxl)
library(stringr)
```


# Problem 1

```{r}
# Read data
nyc_transit_data <- read.csv("hw2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")

# Retain columns
nyc_transit_cleaned <- nyc_transit_data %>%
  select(Line, Station.Name, Station.Latitude, Station.Longitude, 
         Route1, Route2, Route3, Route4, Route5, Route6, Route7, Route8, 
         Route9, Route10, Route11, Entry, Vending, Entrance.Type, ADA) %>%
  clean_names()

# Convert "entry"
nyc_transit_cleaned <- nyc_transit_cleaned %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The cleaned dataset contains `r ncol(nyc_transit_cleaned)` columns and `r nrow(nyc_transit_cleaned)` rows. The variables include:

**line:** The subway line serving the station\
**station_name:** The name of the station\
**station_latitude / station_longitude:** Geographical coordinates of the station\
**route1 to route11:** The subway routes serving the station\
**entry:** Indicates whether entry is allowed at this entrance (converted to a logical variable: True for "YES," False for "NO")\
**vending:** Describes whether vending machines are present\
**entrance_type:** Type of entrance\
**ada:** Indicates if the station is ADA (Americans with Disabilities Act) compliant\

**Data Cleaning Steps**

1. Selected relevant columns.\
2. Renamed columns to follow a consistent lowercase format with underscores.\
3. Converted the "entry" variable from "YES"/"NO" to a logical (True/False) variable.\

The resulting dataset is tidy since each variable is in its own column, and each observation occupies a single row.

**1. How many distinct stations are there?**

```{r}
distinct_stations <- nyc_transit_cleaned %>%
  distinct(line, station_name) %>%
  nrow()
print(distinct_stations)
```

There are `r distinct_stations` distinct stations.

**2. How many stations are ADA compliant?**

```{r}
ada_compliant_stations <- nyc_transit_cleaned %>%
  filter(ada == TRUE) %>%
  distinct(line, station_name) %>%
  nrow()
print(ada_compliant_stations)
```

There are `r ada_compliant_stations` stations that are ADA compliant.

**3. What proportion of station entrances/exits without vending allow entry?**

```{r}
proportion_no_vending_entry <- nyc_transit_cleaned %>%
  filter(vending == "NO") %>%
  summarise(proportion = mean(entry, na.rm = TRUE)) %>%
  pull(proportion)
print(proportion_no_vending_entry)
```

There is the proportion of `r proportion_no_vending_entry` station entrances / exits without vending allow entrance.

```{r}
# Make all route columns are of the same data type (character)
nyc_transit_cleaned <- nyc_transit_cleaned %>%
  mutate(across(route1:route11, as.character))

# Reformat data
nyc_transit_routes = 
  pivot_longer(
    nyc_transit_cleaned, 
    route1:route11,
    names_to = "route_number", 
    values_to = "route_name")
```

**How many distinct stations serve the A train?**

```{r}
stations_serving_A <- nyc_transit_routes %>%
  filter(route_name == "A") %>%
  distinct(line, station_name) %>%
  nrow()
print(stations_serving_A)
```

There are `r stations_serving_A` distinct stations serve the A train.

**Of the stations that serve the A train, how many are ADA compliant?**

```{r}
ada_compliant_stations_A <- nyc_transit_routes %>%
  filter(route_name == "A", ada == TRUE) %>%
  distinct(line, station_name) %>%
  nrow()
print(ada_compliant_stations_A)
```

There are `r ada_compliant_stations_A` that are ADA compliant of the stations that serve the A train.


# Problem 2

**Mrs Trash Wheel**

```{r, message=FALSE}
mr_trash_wheel <- read_excel("hw2_data/202409 Trash Wheel Collection Data.xlsx", 
                             sheet = "Mr. Trash Wheel") %>%
  clean_names() %>%
  select(-starts_with("X")) %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = as.integer(round(as.numeric(sports_balls), 0)), 
         trash_wheel = "Mr. Trash Wheel") 

head(mr_trash_wheel)
```

**Professor Trash Wheel**

```{r}
prof_trash_wheel <- read_excel("hw2_data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Professor Trash Wheel") %>%
  clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(year = as.character(year),
         trash_wheel = "Professor Trash Wheel")

head(prof_trash_wheel)
```

**Gwynnda Trash Wheel**

```{r}
gwynnda_trash_wheel <- read_excel("hw2_data/202409 Trash Wheel Collection Data.xlsx", 
                                  sheet = "Gwynnda Trash Wheel") %>%
  clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(year = as.character(year),
         trash_wheel = "Gwynnda Trash Wheel")  

head(gwynnda_trash_wheel)
```

**Combined dataset**

```{r}
combined_trash_wheel_data <- bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)
head(combined_trash_wheel_data)
```

The combined trash wheel dataset contains a total of `r nrow(combined_trash_wheel_data)` observations, merging data from Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. The dataset consists of `r nrow(mr_trash_wheel)` observations from Mr. Trash Wheel, `r nrow(prof_trash_wheel)` from Professor Trash Wheel, and `r nrow(gwynnda_trash_wheel)` from Gwynnda Trash Wheel. Key variables in this dataset include `year`, `month`, and `date`, which indicate the time period when each observation was recorded, and `dumpster`, which represents the dumpster number used for each trash collection; `weight_tons`, showing the total weight of trash collected in tons; and `plastic_bottles`, which indicates the number of plastic bottles collected during each trash collection. Additionally, `cigarette_butts` counts the total number of cigarette butts collected, while `sports_balls` captures the number of sports balls found. Another significant variable is `homes_powered`, which estimates the number of homes that could be powered by the energy generated from the collected trash. 

```{r}
# Total weight by Professor Trash Wheel
total_weight_professor <- combined_trash_wheel_data %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  summarise(total_weight = sum(as.numeric(weight_tons), na.rm = TRUE)) %>%
  pull(total_weight)

print(total_weight_professor)

# Total number of cigarette butts by Gwynnda
total_cig_butts_gwynnda_june <- combined_trash_wheel_data %>%
  filter(trash_wheel == "Gwynnda Trash Wheel", month == "June", year == "2022") %>%
  summarise(total_cig_butts = sum(as.numeric(cigarette_butts), na.rm = TRUE)) %>%
  pull(total_cig_butts)

print(total_cig_butts_gwynnda_june)
```

According to the data, the total weight of trash collected by Professor Trash Wheel was `r total_weight_professor` tons. Gwynnda Trash Wheel collected `r total_cig_butts_gwynnda_june` cigarette butts in June of 2022.


# Problem 3

```{r}
# Load data
bakers <- read.csv("hw2_data/gbb_datasets/bakers.csv")
bakes <- read.csv("hw2_data/gbb_datasets/bakes.csv")
results <- read.csv("hw2_data/gbb_datasets/results.csv", skip = 2)

# Clean data
bakers_clean <- bakers %>% clean_names()
bakes_clean <- bakes %>% clean_names()
results_clean <- results %>% clean_names()
```

```{r}
# Check bakers in 'results' not present in 'bakers'
missing_bakers_in_results <- anti_join(results_clean, bakers_clean, 
                                       by = c("baker" = "baker_name"))
# print(missing_bakers_in_results)

# Check bakers in 'bakers' not present in 'results'
missing_bakers_in_bakers <- anti_join(bakers_clean, results_clean, 
                                      by = c("baker_name" = "baker"))
# print(missing_bakers_in_bakers)

# Check bakes that do not have corresponding entries in 'results'
missing_bakes_in_results <- 
  anti_join(bakes_clean, results_clean, by = c("baker" = "baker", 
                                   "series" = "series", 
                                   "episode" = "episode"))
# print(missing_bakes_in_results)

# Check bakers in 'bakes' that do not have corresponding entries in 'bakers'
missing_bakers_in_bakes <- anti_join(bakes_clean, bakers_clean, 
                                     by = c("baker" = "baker_name"))
# print(missing_bakers_in_bakes)
```

```{r}
# Fix "name" problem
bakers_clean <- bakers_clean %>%
  mutate(first_name = word(`baker_name`, 1))
```

```{r}
# Merge data
combined_data <- merge(bakers_clean, results_clean, by.x = c("first_name", "series"), 
                       by.y = c("baker", "series"), all.x = TRUE)

final_combined_data <- merge(combined_data, bakes_clean, 
                             by.x = c("first_name", "series", "episode"), 
                             by.y = c("baker", "series", "episode"), all.x = TRUE)

# Remove unnecessary columns
final_combined_data <- final_combined_data %>% select(-first_name)

# Export the final cleaned dataset
write_csv(final_combined_data, "hw2_data/gbb_datasets/final_combined_data.csv")
```

**Data Cleaning Process**

I started by importing the `bakers`, `bakes`, and `results` datasets and then cleaned them using the `clean_names()` function from the `janitor` package to convert all column names to a consistent format (lowercase and underscores).

During the data validation process using `anti_join()`, I identified discrepancies between the datasets:

All bakers listed in `results` were not present in the `bakers` dataset, and vice versa.\
Similarly, all bakers in `bakes` were missing in the `bakers` dataset.

One major challenge I encountered was that the `baker_name` column in the `bakers` dataset contained full names, while the `results` and `bakes` datasets only used first names. To address this, I used `mutate()` and `word()` to extract the first name from `baker_name` and create a new `first_name` column in the `bakers` dataset, which allowed for accurate merging.

Next, I merged `bakers_clean` with `results_clean` using the `first_name` and `series` columns. Afterward, I merged the resulting dataset with `bakes_clean` using `first_name`, `series`, and `episode` as the merging keys.

Finally, I removed any unnecessary columns and exported the clean, merged dataset as final_combined_data.csv.

**Discussion of the Final Dataset**

The final dataset effectively combines information about each baker, their performances, and their bakes across all episodes. It includes details such as the full name of each baker, the series and episode they participated in, their technical challenge results, and the specifics of their bakes. Despite the challenge of dealing with inconsistent name formats, the cleaning and merging process resulted in a comprehensive, well-structured dataset ready for analysis.

```{r}
# Filter for Seasons 5 through 10 and for Star Baker or Winner results
star_bakers_winners <- final_combined_data %>%
  filter(series %in% c(5, 6, 7, 8, 9, 10) & grepl("STAR BAKER|WINNER", result, ignore.case = TRUE)) %>%
  select(series, episode, baker_name, result) %>%
  arrange(series, episode)

# Display the resulting table
print(star_bakers_winners)
```

### Comment on the Table

**Predictable Overall Winners:** Contestants who consistently earned the "Star Baker" title across multiple episodes demonstrated strong performance and could have been expected to win the overall competition.

**Surprises:**  There were some bakers who didn't earn the "Star Baker" title at all throughout the competition but still managed to win the overall title, making their victory quite unexpected.

```{r}
# Import the viewership data
viewers <- read_csv("hw2_data/gbb_datasets/viewers.csv", show_col_types = FALSE)

# Clean the column names
viewers <- viewers %>% clean_names()

# Display the first 10 rows of the cleaned dataset
head(viewers, 10)

# Calculate the average viewership for Season 1 and Season 5
avg_viewership_season1 <- viewers %>%
  pull(series_1) %>%
  mean(na.rm = TRUE)

avg_viewership_season5 <- viewers %>%
  pull(series_5) %>%
  mean(na.rm = TRUE)

# Display the average viewership results
avg_viewership_season1
avg_viewership_season5
```

The average viewership in Season 1 is `r avg_viewership_season1` and the average viewership in Season 5 is `r avg_viewership_season5`.